input {
	http {
		id => "AppMon ProtoBuf decode"
		port => 8080
		codec => protobuf {
			class_name => "Export::Bt::BusinessTransactions"
			include_path => ['/opt/logstash-5.5.2/etc/dt_bt_export.rb']
		}
	}
}

filter {
   	split { id => "BT split" field => "businessTransactions" add_tag => ["btsplit"]}
	if ("btsplit" in [tags]) {
		split { id => "BT occurrence split" field => "[businessTransactions][occurrences]" add_tag => ["btoccurrence"] remove_tag => ["btsplit"] }
	}
	else {
		mutate {
                        add_tag => ["leftover"]
                }
	}
   
	if ("btoccurrence" in [tags]) {

	mutate {
		id => "Adding Basic Tags"
		add_tag => [ "application", "serverName", "systemProfile" ]
	}

	# BusinessTransaction type=1 (Page Action BT)
        # if the BusinessTransaction is a Visit BT there is no Responsetime, we remove the field again
        #  
	if ( [businessTransactions][type] == 1 ) {
		mutate {
			id => "Copy Page Action BT fields"
			copy => {
				"[businessTransactions][occurrences][clientTime]" => "clientTime"
				"[businessTransactions][occurrences][serverTime]" => "serverTime"
			}
		}
	}
	
	mutate {
		# temporary fields for BT splitting measures and their values (will become tags)
		id => "Copy BT splitting measures and values"
		copy => { 
			"[businessTransactions][dimensionNames]" => "tagging_names"
			"[businessTransactions][occurrences][dimensions]" => "tagging_values"
                	"[businessTransactions][measureNames]" => "resultmeasure_names"
                	"[businessTransactions][occurrences][values]" => "resultmeasure_values"
			"[businessTransactions][application]" => "application"
			"[businessTransactions][name]" => "businesstransaction"
			"[businessTransactions][systemProfile]" => "systemProfile"
			"[businessTransactions][occurrences][responseTime]" => "responseTime"
			"[businessTransactions][occurrences][startTime]" => "time"
			
		}
	}

	# BusinessTransaction type=2 (Visit BT)
	# if the BusinessTransaction is a Visit BT there is no ResponseTime, we remove the field again
	if ( [businessTransactions][type] == 2 ) {
		mutate {
			id => "Visit BT processing"
			remove_field => [ "responseTime" ]
			copy => {
				"[businessTransactions][occurrences][clientIP]" => "clientIP"
				"[businessTransactions][occurrences][clientFamily]" => "clientFamily"
				"[businessTransactions][occurrences][continent]" => "continent"
				"[businessTransactions][occurrences][country]" => "country"
				"[businessTransactions][occurrences][city]" => "city"
				"[businessTransactions][occurrences][failedActions]" => "failedActions"
				"[businessTransactions][occurrences][clientErrors]" => "clientErrors"
				"[businessTransactions][occurrences][osFamily]" => "osFamily"
				"[businessTransactions][occurrences][osName]" => "osName"
				"[businessTransactions][occurrences][apdex]" => "apdex"
				"[businessTransactions][occurrences][converted]" => "converted"
			}
			add_tag => [ "clientIP", "clientFamily", "continent", "country", "city", "osFamily", "osName", "converted"]
		}
		geoip {
			id => "GeoIP calculation"
  			source => "clientIP"
 			target => "geoip"
  			database => "/opt/logstash-5.5.2/etc/GeoLite2-City.mmdb"
			fields => [ "continent_code","country_code2", "latitude", "longitude" ]
  			add_tag => [ "continent_code", "country_code2", "geohash" ]
  			add_field => { 
				"continent_code" => "%{[geoip][continent_code]}"
				"country_code2" => "%{[geoip][country_code2]}"
				"geohash" => "none"
				"location" => [ "%{[geoip][longitude]}", "%{[geoip][latitude]}" ]
			}
		}
		#
		# calculating our own geohash code for mapping on grafana's worldmap
		#
		ruby {
			id => "GeoHash calculation"
			code => "
				def encode(latitude, longitude, precision=12)
						latlng = [latitude, longitude]
						points = [[-90.0, 90.0], [-180.0, 180.0]]
						is_lng = 1
						(0...precision).map {
  							ch = 0
  							5.times do |bit|
    							mid = (points[is_lng][0] + points[is_lng][1]) / 2
    							points[is_lng][latlng[is_lng] > mid ? 0 : 1] = mid
    							ch |=  [0x10, 0x08, 0x04, 0x02, 0x01][bit] if latlng[is_lng] > mid
    							is_lng ^= 1
  							end
  							'0123456789bcdefghjkmnpqrstuvwxyz'[ch,1]
						}.join
				end
				
				begin
                                        geohash = ('%s' % encode(event.get('[geoip][latitude]').to_f,event.get('[geoip][longitude]').to_f,5))
                                rescue
                                        #couldn't convert/or didn't get any result in geoip location
                                else
                                        event.set('geohash', geohash)
                                end
			"
		}	
	}
	ruby {
		id => "BT splitting and result measure calculation"
    		code => "
    			# we extract and use the system Profile name and create a project field to later use as dynamic database name
    			# format usually is PROJECT_Production, PROJ_Staging => all stored in proj_dtmetrics
			project = ('%s' % event.get('systemProfile').split('_')[0].downcase)
			event.set('project',project)
						
			# get all BT result measures and their values, these are numeric so we make sure to save them as float
        		resultmeasures = event.get('resultmeasure_names')
			resultvalues = event.get('resultmeasure_values')
			resultmeasures.each_with_index { |measure,idx| 
				measure.gsub! ' ', '_'
            			measure.gsub! '(', ''
				measure.gsub! ')', ''
				unless resultvalues[idx].nil?
					#event.set(measure, ('%.3f' % resultvalues[$i]).to_f)
					event.set(measure, resultvalues[idx])
				else
					event.set(measure,0.000)
				end
        		}
			
			# get all BT splitting measures and their values, these are string values 
			taggingvalues = event.get('tagging_values')
			taggingnames = event.get('tagging_names')
			#puts taggingvalues +' : '+ taggingnames
			taggingnames.each_with_index { |tag, idx|
				tag.gsub! ' ', '_'
				tag.gsub! '(', ''
				tag.gsub! ')', ''
				unless taggingvalues[idx].nil?
					event.set(tag,taggingvalues[idx])
				else
					event.set(tag,'n/a')
				end
			}
			# get the existing tags and add the BT splitting measure names to it so that they are submitted to influx as tags not fields
			event.set('tags',event.get('tags').push(*taggingnames))
    		"
		}
	date {
		match => [ "time", "UNIX_MS" ]
	}
	
	#remove unneeded and temporary data from event
	mutate {
		id => "Clean up event"
		remove_field => [ "headers","host","businessTransactions","resultmeasure_names","resultmeasure_values", "tagging_names", "tagging_values" , "@version", "sequence", "message", "type", "geoip", "clientIP", "_geoip_lookup_failure", "_rubyexception"]
		# remove the clientIP to avoid tag limit overflow in influxdb (not needed anyway, maybe reduce IP to subnets), also remove eventual error tags
		remove_tag => [ "clientIP", "_geoip_lookup_failure", "_rubyexception", "btoccurrence"]
	}
	}
	else {
		mutate {
			add_tag => ["leftover"]
		}
	}
}

output {
	#file {
	#	path => "/tmp/%{[project]}.logstash.out"
	#}
	#stdout { codec => rubydebug }
	
	if ( [project] == "sme") {	
	influxdb {
		id => "InfluxDB Output"
		host => "10.32.23.254"
		port => "8187"
		# to use a database that uses the project code
		db => "%{[project]}"
		retention_policy => "default"
		#db => "dynatrace"
		allow_time_override => true
		coerce_values => {
			"responseTime" => "float"
			"clientTime" => "float"
            		"serverTime" => "float"
            		"failedActions" => "float"
            		"clientErrors" => "float"
        	    	"apdex" => "float"
	        }
		measurement => "%{[businesstransaction]}"
		exclude_fields => [ "businesstransaction", "@timestamp", "@version", "sequence", "message", "type", "project", "location"]
		use_event_fields_for_data_points => true
	}
	}
}
