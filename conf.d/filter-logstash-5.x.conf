input {
	http {
		port => 8080
		codec => protobuf {
			class_name => "Export::Bt::BusinessTransactions"
			include_path => ['/opt/logstash-5.5.2/etc/dt_bt_export.rb']
		}
		threads => 4
	}
}

filter {
   	split { field => "businessTransactions" }
	split { field => "[businessTransactions][occurrences]" }
   
	mutate {
		add_tag => [ "application", "serverName", "systemProfile" ]
	}

	# BusinessTransaction type=1 (Page Action BT)
        # if the BusinessTransaction is a Visit BT there is no Responsetime, we remove the field again
        #  
	if ( [businessTransactions][type] == 1 ) {
		mutate {
			add_field => {
				"clientTime" => '%{[businessTransactions][occurrences][clientTime]}'
            			"serverTime" => '%{[businessTransactions][occurrences][serverTime]}'
				#"apdex" => "%{[businessTransactions][occurrences][apdex]}"
			}
		}
	}
	
	mutate {
		add_field => {
			# temporary fields for BT splitting measures and their values (will become tags)
			"tagging_names" => "%{[businessTransactions][dimensionNames]}"
			"tagging_values" => "%{[businessTransactions][occurrences][dimensions]}"
			"application" => "%{[businessTransactions][application]}"
			"businesstransaction" => "%{[businessTransactions][name]}"
			"systemProfile" => "%{[businessTransactions][systemProfile]}"
			"responseTime" => "%{[businessTransactions][occurrences][responseTime]}"
			"time" => "%{[businessTransactions][occurrences][startTime]}"
			"resultmeasure_names" => "%{[businessTransactions][measureNames]}"
			"resultmeasure_values" => "%{[businessTransactions][occurrences][values]}"
		}
	}

	# BusinessTransaction type=2 (Visit BT)
	# if the BusinessTransaction is a Visit BT there is no ResponseTime, we remove the field again
	if ( [businessTransactions][type] == 2 ) {
		mutate {
			remove_field => [ "responseTime" ]
			add_field => { 
				"clientIP" => "%{[businessTransactions][occurrences][clientIP]}"
				"clientFamily" => "%{[businessTransactions][occurrences][clientFamily]}"
				"continent" => "%{[businessTransactions][occurrences][continent]}"
				"country" => "%{[businessTransactions][occurrences][country]}"
				"city" => "%{[businessTransactions][occurrences][city]}"
				"failedActions" => "%{[businessTransactions][occurrences][failedActions]}"
				"clientErrors" => "%{[businessTransactions][occurrences][clientErrors]}"
				"osFamily" => "%{[businessTransactions][occurrences][osFamily]}"
				"osName" => "%{[businessTransactions][occurrences][osName]}"
				"apdex" => "%{[businessTransactions][occurrences][apdex]}"
				"converted" => "%{[businessTransactions][occurrences][converted]}"					
			}
			add_tag => [ "clientIP", "clientFamily", "continent", "country", "city", "osFamily", "osName", "converted"]
		}
		geoip {
  				source => "clientIP"
 				target => "geoip"
  				database => "/opt/logstash-5.5.2/etc/GeoLite2-City.mmdb"
				fields => [ "continent_code","country_code2", "latitude", "longitude" ]
  				add_tag => [ "continent_code", "country_code2", "geohash" ]
  				add_field => { 
					"continent_code" => "%{[geoip][continent_code]}"
					"country_code2" => "%{[geoip][country_code2]}"
					"geohash" => "none"
					"location" => [ "%{[geoip][longitude]}", "%{[geoip][latitude]}" ]
				}
		}
		#
		# calculating our own geohash code for mapping on grafana's worldmap
		#
		ruby {
			code => "
				def encode(latitude, longitude, precision=12)
						latlng = [latitude, longitude]
						points = [[-90.0, 90.0], [-180.0, 180.0]]
						is_lng = 1
						(0...precision).map {
  							ch = 0
  							5.times do |bit|
    							mid = (points[is_lng][0] + points[is_lng][1]) / 2
    							points[is_lng][latlng[is_lng] > mid ? 0 : 1] = mid
    							ch |=  [0x10, 0x08, 0x04, 0x02, 0x01][bit] if latlng[is_lng] > mid
    							is_lng ^= 1
  							end
  							'0123456789bcdefghjkmnpqrstuvwxyz'[ch,1]
						}.join
				end
				
				begin
                		geohash = ('%s' % encode(event.get('[geoip][latitude]').to_f,event.get('[geoip][longitude]').to_f,5))
                rescue
                        #couldn't convert/or didn't get any result in geoip location
                else
                        event.set('geohash', geohash)
                end
			"
		}	
	}
	ruby {
    		code => "
    			# we extract and use the system Profile name and create a project field to later use as dynamic database name
    			# format usually is PROJECT_Production, PROJ_Staging => all stored in proj_dtmetrics
			project = ('%s' % event.get('systemProfile').split('_')[0].downcase)
			event.set('project',project)
			
			# get all BT result measures and their values, these are numeric so we make sure to save them as float
        		resultmeasures = event.get('resultmeasure_names')
			resultvalues = event.get('resultmeasure_values')
			$i = 0
			resultmeasures.each { |measure| 
				measure.gsub! ' ', '_'
            			measure.gsub! '(', ''
				measure.gsub! ')', ''
				event.set(measure, ('%.3f' % resultvalues[$i]).to_f)
				$i +=1
        		}
			
			# get all BT splitting measures and their values, these are string values 
			taggingvalues = event.get('tagging_values')
			taggingnames = event.get('tagging_names')
			$i =0
			taggingnames.each { |tag|
				tag.gsub! ' ', '_'
				tag.gsub! '(', ''
				tag.gsub! ')', ''
				event.set(tag, taggingvalues[$i])
				$i +=1
			}
			# get the existing tags and add the BT splitting measure names to it so that they are submitted to influx as tags not fields
			event.set('tags',event.get('tags').push(*taggingnames))
    		"
		}
	date {
		match => [ "time", "UNIX_MS" ]
	}
	
	#remove unneeded and temporary data from event
	mutate {
		remove_field => [ "headers","host","businessTransactions","resultmeasure_names","resultmeasure_values", "tagging_names", "tagging_values" , "@version", "sequence", "message", "type", "geoip", "clientIP", "_geoip_lookup_failure", "_rubyexception"]
		# remove the clientIP to avoid tag limit overflow in influxdb (not needed anyway, maybe reduce IP to subnets), also remove eventual error tags
		remove_tag => [ "clientIP", "_geoip_lookup_failure", "_rubyexception" ]
	}
}

output {
	#file {
	#	path => "/tmp/%{[project]}.logstash.out"
	#}
	#stdout { codec => rubydebug }

	# discard unwanted projects (temporary)
	if ( [project] == "sme" or [project] == "evy" ) {
	
	#file { path => "/tmp/%{[project]}.logstash.out" }
	
	influxdb {
		host => "localhost"
		# to use a database that uses the project code
		db => "%{[project]}_dtmetrics"
		#db => "dynatrace"
		allow_time_override => true
		coerce_values => {
			"responseTime" => "float"
			"clientTime" => "float"
            		"serverTime" => "float"
            		"failedActions" => "float"
            		"clientErrors" => "float"
        	    	"apdex" => "float"
	        }
		measurement => "%{[businesstransaction]}"
		exclude_fields => [ "businesstransaction", "@timestamp", "@version", "sequence", "message", "type", "project", "location"]
		use_event_fields_for_data_points => true
	}

	}
}
